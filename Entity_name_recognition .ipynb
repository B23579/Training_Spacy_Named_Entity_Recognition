{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33fe92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd894f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa80006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_analyze = ('Hello code & Supply,'\n",
    "       'my name ins Josh and tonight'\n",
    "       'we\\' re in Pittsburgh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615acd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a68e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Josh', 'PERSON'), ('Pittsburgh', 'GPE')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Josh', 'PERSON'), ('Pittsburgh', 'GPE')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = [(x.text,x.label_) for x in doc.ents]\n",
    "print(ents)\n",
    "ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5892d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the phrase matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62df77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "341c014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"CIADIR\"\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "for i in ['Gina Haspel', 'Gina', 'Haspel']:\n",
    "    matcher.add(label,None,nlp(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3daad705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17539557946531887154, 0, 1),\n",
       " (17539557946531887154, 0, 2),\n",
       " (17539557946531887154, 1, 2)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = nlp('Gina Haspel was nominated in 2018')\n",
    "matches =  matcher(one)\n",
    "[match for match in matches] # reprentation of label, to extract information from \n",
    "# this, we will we the utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b34bb2",
   "metadata": {},
   "source": [
    "This function convert the output of the PhraseMacher to something usable in training. The training data needs a string index of characters(start, end, label) while the matched output uses index of words from nlp document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "919f8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offseter(lbl, doc, matchitem):\n",
    "    o_one = len(str(doc[0:matchitem[1]]))\n",
    "    subdoc = doc[matchitem[1]:matchitem[2]]\n",
    "    o_two = o_one + len(str(subdoc))\n",
    "    return (o_one, o_two,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaea021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b02dbb",
   "metadata": {},
   "source": [
    "## Setup the phrase matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c00f1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Cov\"\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "for i in ['test','Covid-19', 'Laboratories']:\n",
    "    matcher.add(label,None,nlp(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed04df",
   "metadata": {},
   "source": [
    "## Gather training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4e371e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "to_train_ents = []\n",
    "\n",
    "with open('text.txt') as gh:\n",
    "    line =  True\n",
    "    compt = 0\n",
    "    while line: \n",
    "        line =  gh.readline()\n",
    "        mnlp_line = nlp(line)\n",
    "        matches = matcher(mnlp_line)\n",
    "        res = [offseter(label, mnlp_line,x)\n",
    "              for x in matches]\n",
    "        to_train_ents.append((line, dict(entities = res)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30596c9c",
   "metadata": {},
   "source": [
    "## Train the Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6a201af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nlp.begin_training()\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe !='ner']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0c42bc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "da30c0ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-296b4c5afa5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_train_ents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we shuffle the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_train_ents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffsets_to_biluo_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             nlp.update([example],\n\u001b[0;32m      8\u001b[0m             \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\training\\iob_utils.py\u001b[0m in \u001b[0;36moffsets_to_biluo_tags\u001b[1;34m(doc, entities, missing)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mbiluo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"-\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;31m# Handle entity cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstart_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstarts\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# account for many-to-one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes): # only train NER\n",
    "    for itn in range(20): # we are going to go throught the training data 20 times\n",
    "        losses = {}\n",
    "        random.shuffle(to_train_ents) # we shuffle the data \n",
    "        for item in to_train_ents:\n",
    "            example = Example.from_dict(nlp.make_doc(item[0]), item[1])\n",
    "            nlp.update([example],\n",
    "            sgd=optimizer,\n",
    "            drop = 0.35,\n",
    "            losses =  losses)\n",
    "            #print(\"Ner\",losses[\"ner\"])\n",
    "            # this update function Takes \n",
    "                       # the model we updated at the begininig at update it with the new information\n",
    "                       #about the tokens, the position of the tokens and the string.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e4a58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16114187870790477818, 2, 3), (16114187870790477818, 7, 8)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = nlp(' data test-to-treat Laboratories program stymied by lack of services, tech problems')\n",
    "matches =  matcher(one)\n",
    "[match for match in matches] # reprentation of label, to extract information from \n",
    "# this, we will we the utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2fa8f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in one.ents:\n",
    "    print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bca26839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for text,_ in to_train_ents:\n",
    "    doc = nlp(text)\n",
    "    result = [(ent,ent.label_) for ent in doc.ents]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed00585c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Efforts to streamline delivery of at-home test results\\n',\n",
       " {'entities': [(33, 40, 'Covid')]})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_train_ents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b280a91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"States like Tennessee encourage people who use at-home tests to submit their results to the manufacturers so they can be tracked. It's unclear how many people actually do that, but there are several efforts underway to track home tests better.\\n\",\n",
       "  {'entities': [(46, 53, 'Covid')]}),\n",
       " ('Efforts to streamline delivery of at-home test results\\n',\n",
       "  {'entities': [(33, 40, 'Covid')]}),\n",
       " ('The Association of Public Health Laboratories announced in March that it was awarded the NIH contract, limited to $8.8 million over three years, to work on improving the reporting of over-the-counter at-home Covid-19 test results to public health officials. The contract employs AIMS to collect data from at-home test manufacturers and then distribute the data to states and jurisdictions.\\n',\n",
       "  {'entities': [(32, 44, 'Covid'),\n",
       "    (199, 206, 'Covid'),\n",
       "    (207, 215, 'Covid'),\n",
       "    (304, 311, 'Covid')]}),\n",
       " ('Another platform pushing for more efficiency is ReportStream, a cloud-based data routing system set up by the US Digital Service in partnership with the US Centers for Disease Control and Prevention.',\n",
       "  {'entities': []}),\n",
       " ('Covid-19 test-to-treat program stymied by lack of services, tech problems\\n',\n",
       "  {'entities': [(0, 8, 'Covid')]}),\n",
       " ('\"An at-home test has a digital tool that goes with it, and we\\'re trying to build out, essentially, a spec that allows the data to flow through the hub to the places where it needs to get for state reporting,\" Becker said. \"There are states that are interested in getting that data and that\\'s really for situational awareness.\"\\n',\n",
       "  {'entities': [(3, 10, 'Covid')]}),\n",
       " ('', {'entities': []}),\n",
       " ('The initiative \"is in recognition of the fact that this gap exists in reporting,\" Becker said.\\n',\n",
       "  {'entities': []}),\n",
       " ('\"From a public health perspective, that\\'s sort of a missing data point, if you will, in the universe of testing,\" Becker said of at-home test results. \"That\\'s kind of a blind spot.\"\\n',\n",
       "  {'entities': [(128, 135, 'Covid')]}),\n",
       " ('This approach still relies on people who use at-home tests to report their results to manufacturers, but Association of Public Health Laboratories CEO Scott Becker hopes the AIMS system eases the process of manufacturers reporting to public health authorities.\\n',\n",
       "  {'entities': [(44, 51, 'Covid'), (133, 145, 'Covid')]}),\n",
       " ('Covid-19 test-to-treat program stymied by lack of services, tech problems\\n',\n",
       "  {'entities': [(0, 8, 'Covid')]}),\n",
       " (\"The Association of Public Health Laboratories is working with the NIH under a contract to use the association's electronic lab reporting platform, AIMS, to help streamline the reporting of Covid-19 home test results.\\n\",\n",
       "  {'entities': [(32, 44, 'Covid'), (188, 196, 'Covid')]})]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_train_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "835f5d31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN_DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-f3d908ae1504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTRAIN_DATA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'TRAIN_DATA' is not defined"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA[1:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
