{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421b56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pkgs\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7d39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLP Pkgs\n",
    "import spacy\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from spacy.util import minibatch, compounding\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a593139f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"drug_review_dataset_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd13106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>drug_class</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "      <td>arb blocker</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168333</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067210</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179545</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  drugName                     condition  \\\n",
       "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260                Guanfacine                          ADHD   \n",
       "2       92703                    Lybrel                 Birth Control   \n",
       "3      138000                Ortho Evra                 Birth Control   \n",
       "4       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...     9.0   \n",
       "1  \"My son is halfway through his fourth week of ...     8.0   \n",
       "2  \"I used to take another oral contraceptive, wh...     5.0   \n",
       "3  \"This is my first time using any form of birth...     8.0   \n",
       "4  \"Suboxone has completely turned my life around...     9.0   \n",
       "\n",
       "                date  usefulCount   drug_class  sentiment sentiment_label  \n",
       "0       May 20, 2012           27  arb blocker   0.000000         neutral  \n",
       "1     April 27, 2010          192          NaN   0.168333        positive  \n",
       "2  December 14, 2009           17          NaN   0.067210        positive  \n",
       "3   November 3, 2015           10          NaN   0.179545        positive  \n",
       "4  November 27, 2016           37          NaN   0.194444        positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19de9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER\n",
    "nlp0 = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e5d354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get All Components of this NLP Object\n",
    "nlp0.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "264b98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner0 = nlp0.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06bcc7f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_label() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-023447a2bc2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mner0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: add_label() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b196db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "ex1 = \"James went to London to buy Ibuprofen last year 2019\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eb00b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx = nlp0(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ec4337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5445ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London GPE\n",
      "Ibuprofen ORG\n",
      "last year 2019 DATE\n"
     ]
    }
   ],
   "source": [
    "# Check for entities\n",
    "for entity in docx.ents:\n",
    "    print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591072e",
   "metadata": {},
   "source": [
    "### Preparing the data \n",
    "\n",
    "Training data must be a tuple\n",
    "\n",
    "TRAIN_DATA = [ (\"Who is Shaka Khan?\", {\"entities\": [(START, STOP, \"LABEL\")]}) ]\n",
    "\n",
    "\n",
    "TRAIN_DATA = [ (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}), (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32c9cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    processed_token = []\n",
    "    for token in review.split():\n",
    "        token = ''.join(e.lower() for e in token if e.isalnum())\n",
    "        processed_token.append(token)\n",
    "    return ' '.join(processed_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b220c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drugs Names\n",
    "all_drugs = df['drugName'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e8861edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_drugs = [x.lower() for x in all_drugs]\n",
    "all_drugs==\"testim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4f54433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         \"It has no side effect, I take it in combinati...\n",
       "1         \"My son is halfway through his fourth week of ...\n",
       "2         \"I used to take another oral contraceptive, wh...\n",
       "3         \"This is my first time using any form of birth...\n",
       "4         \"Suboxone has completely turned my life around...\n",
       "                                ...                        \n",
       "161292    \"I wrote my first report in Mid-October of 201...\n",
       "161293    \"I was given this in IV before surgey. I immed...\n",
       "161294    \"Limited improvement after 4 months, developed...\n",
       "161295    \"I&#039;ve been on thyroid medication 49 years...\n",
       "161296    \"I&#039;ve had chronic constipation all my adu...\n",
       "Name: review, Length: 161297, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd942d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "TRAIN_DATA = []\n",
    "for _, item in df.iterrows():\n",
    "    ent_dict = {}\n",
    "    if count < 1000:\n",
    "        review = process_review(item['review'])\n",
    "        #Locate drugs and their positions once and add to the visited items.\n",
    "        visited_items = []\n",
    "        entities = []\n",
    "        for token in review.split():\n",
    "            if token in all_drugs:\n",
    "                for i in re.finditer(token, review):\n",
    "                    if token not in visited_items:\n",
    "                        entity = (i.span()[0], i.span()[1], 'DRUG')\n",
    "                        visited_items.append(token)\n",
    "                        entities.append(entity)\n",
    "        if len(entities) > 0:\n",
    "            ent_dict['entities'] = entities\n",
    "            train_item = (review, ent_dict)\n",
    "            TRAIN_DATA.append(train_item)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55d19aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('my son is halfway through his fourth week of intuniv we became concerned when he began this last week when he started taking the highest dose he will be on for two days he could hardly get out of bed was very cranky and slept for nearly 8 hours on a drive home from school vacation very unusual for him i called his doctor on monday morning and she said to stick it out a few days see how he did at school and with getting up in the morning the last two days have been problem free he is much more agreeable than ever he is less emotional a good thing less cranky he is remembering all the things he should overall his behavior is better we have tried many different medications and so far this is the most effective',\n",
       "  {'entities': [(45, 52, 'DRUG')]}),\n",
       " ('i used to take another oral contraceptive which had 21 pill cycle and was very happy very light periods max 5 days no other side effects but it contained hormone gestodene which is not available in us so i switched to lybrel because the ingredients are similar when my other pills ended i started lybrel immediately on my first day of period as the instructions said and the period lasted for two weeks when taking the second pack same two weeks and now with third pack things got even worse my third period lasted for two weeks and now it039s the end of the third week i still have daily brown discharge the positive side is that i didn039t have any other side effects the idea of being period free was so tempting alas',\n",
       "  {'entities': [(218, 224, 'DRUG')]})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188434ec",
   "metadata": {},
   "source": [
    "# Training the NER Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce4117",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43791663",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 20\n",
    "def train_ner(training_data):\n",
    "    \"\"\"Steps\n",
    "    Create a Blank NLP  model object\n",
    "    Create and add NER to the NLP model\n",
    "    Add Labels from your training data\n",
    "    Train  \n",
    "    \"\"\"\n",
    "    TRAIN_DATA = training_data\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "    \n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\",last=True)\n",
    "        #nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            n_samples = len(texts)\n",
    "            for sample, label in zip(texts[:n_samples],annotations[:n_samples]):\n",
    "\n",
    "                    example = Example.from_dict(nlp.make_doc(sample), label)\n",
    "                    nlp.update([example],\n",
    "                        drop=0.35,  # dropout - make it harder to memorise data\n",
    "                        losses=losses,\n",
    "                    )\n",
    "        print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f3802b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Losses {'ner': 794.9302599248563}\n",
      "Losses {'ner': 207.44614014390416}\n",
      "Losses {'ner': 145.95195985568284}\n",
      "Losses {'ner': 110.01973029744478}\n",
      "Losses {'ner': 74.99761658604783}\n",
      "Losses {'ner': 56.762903658675555}\n",
      "Losses {'ner': 71.14993604346088}\n",
      "Losses {'ner': 45.598185051746725}\n",
      "Losses {'ner': 32.22910505117763}\n",
      "Losses {'ner': 39.30490059482556}\n",
      "Losses {'ner': 39.21623854133004}\n",
      "Losses {'ner': 36.34183681086979}\n",
      "Losses {'ner': 29.561587040307394}\n",
      "Losses {'ner': 18.04229876391385}\n",
      "Losses {'ner': 29.246280809232616}\n",
      "Losses {'ner': 22.877774512348118}\n",
      "Losses {'ner': 23.812194081489988}\n",
      "Losses {'ner': 33.40802169101459}\n",
      "Losses {'ner': 17.7297256453721}\n",
      "Losses {'ner': 8.99061670867373}\n"
     ]
    }
   ],
   "source": [
    "# Let training\n",
    "nlp2 = train_ner(TRAIN_DATA[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f62ac15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(androgel, 'DRUG')]\n"
     ]
    }
   ],
   "source": [
    "for text,_ in TRAIN_DATA[:1]:\n",
    "    doc = nlp2(text)\n",
    "    result = [(ent,ent.label_) for ent in doc.ents]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "947e6c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('when i first started using axiron it burned for a few minutes i was afriad this would be the rest of my life nope two weeks later the burning stopped i have tried testim androgel and hated the messy applications and feared spreading it on my nieces this goes under my arm and i love it it is worth the extra 30 dollars from my insurance i do recommend',\n",
       "  {'entities': [(27, 33, 'DRUG'), (163, 169, 'DRUG'), (170, 178, 'DRUG')]})]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe61dc",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b8219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "027c5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nlp.begin_training()\n",
    "to_train_ents = TRAIN_DATA[:100]\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe !='ner']\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes): # only train NER\n",
    "    for itn in range(n_iter): # we are going to go throught the training data 20 times\n",
    "        losses = {}\n",
    "        random.shuffle(to_train_ents) # we shuffle the data \n",
    "        for item in to_train_ents:\n",
    "            example = Example.from_dict(nlp.make_doc(item[0]), item[1])\n",
    "            nlp.update([example],\n",
    "            sgd=optimizer,\n",
    "            drop = 0.35,\n",
    "            losses =  losses)\n",
    "        print(\"Ner\",losses[\"ner\"])\n",
    "            # this update function Takes \n",
    "                       # the model we updated at the begininig at update it with the new information\n",
    "                       #about the tokens, the position of the tokens and the string.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ac69ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(axiron, 'DRUG'), (testim, 'DRUG'), (androgel, 'DRUG')]\n"
     ]
    }
   ],
   "source": [
    "for text,_ in TRAIN_DATA[:1]:\n",
    "    doc = nlp(text)\n",
    "    result = [(ent,ent.label_) for ent in doc.ents]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "815e0ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('when i first started using axiron it burned for a few minutes i was afriad this would be the rest of my life nope two weeks later the burning stopped i have tried testim androgel and hated the messy applications and feared spreading it on my nieces this goes under my arm and i love it it is worth the extra 30 dollars from my insurance i do recommend',\n",
       "  {'entities': [(27, 33, 'DRUG'), (163, 169, 'DRUG'), (170, 178, 'DRUG')]})]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537ea1f",
   "metadata": {},
   "source": [
    "# Extract drog entity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a27e95",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "44ea8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_entity(text):\n",
    "    docx =  nlp2(text)\n",
    "    result = [(ent,ent.label_) for ent in docx.ents]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "16d3320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"It has no side effect, I take it in combinati...\n",
       "1    \"My son is halfway through his fourth week of ...\n",
       "2    \"I used to take another oral contraceptive, wh...\n",
       "3    \"This is my first time using any form of birth...\n",
       "4    \"Suboxone has completely turned my life around...\n",
       "5    \"2nd day on 5mg started to work with rock hard...\n",
       "6    \"He pulled out, but he cummed a bit in me. I t...\n",
       "7    \"Abilify changed my life. There is hope. I was...\n",
       "8    \" I Ve had  nothing but problems with the Kepp...\n",
       "9    \"I had been on the pill for many years. When m...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11a3bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                     [((Intuniv), DRUG), ((.), DRUG)]\n",
       "2                                                   []\n",
       "3                                                   []\n",
       "4    [((Suboxone), DRUG), ((oxycontin), DRUG), ((ox...\n",
       "5              [((!), DRUG), ((!), DRUG), ((!), DRUG)]\n",
       "6                                                   []\n",
       "7    [((Abilify), DRUG), ((Zoloft), DRUG), ((Abilif...\n",
       "8                                                   []\n",
       "9                                    [((older), DRUG)]\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0:10].apply(extract_drug_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed34b03b",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "49a140fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drug_entity_1(text):\n",
    "    docx =  nlp(text)\n",
    "    result = [(ent,ent.label_) for ent in docx.ents]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "03bc68e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 [((Bystolic), DRUG)]\n",
       "1                                  [((Intuniv), DRUG)]\n",
       "2    [((max), DRUG), ((Lybrel), DRUG), ((Lybrel), D...\n",
       "3                                      [((max), DRUG)]\n",
       "4    [((Suboxone), DRUG), ((Suboxone), DRUG), ((oxy...\n",
       "5                                                   []\n",
       "6                                                   []\n",
       "7    [((Abilify), DRUG), ((Zoloft), DRUG), ((Abilif...\n",
       "8                                                   []\n",
       "9                                                   []\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0:10].apply(extract_drug_entity_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d956bf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects. But it contained hormone gestodene, which is not available in US, so I switched to Lybrel, because the ingredients are similar. When my other pills ended, I started Lybrel immediately, on my first day of period, as the instructions said. And the period lasted for two weeks. When taking the second pack- same two weeks. And now, with third pack things got even worse- my third period lasted for two weeks and now it&#039;s the end of the third week- I still have daily brown discharge.\\r\\nThe positive side is that I didn&#039;t have any other side effects. The idea of being period free was so tempting... Alas.\"'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86149e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d07dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
